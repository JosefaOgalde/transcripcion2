{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ9jSLgT+eoglp7bLl7U+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosefaOgalde/transcripcion2/blob/main/Transcripcion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Whisper\n",
        "\n",
        "The commands below will install the Python packages needed to use Whisper models and evaluate the transcription results."
      ],
      "metadata": {
        "id": "5Zww3J2gUXLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ],
      "metadata": {
        "id": "1KzrbKSTTsh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the LibriSpeech dataset\n",
        "\n",
        "The following will load the test-clean split of the LibriSpeech corpus using torchaudio."
      ],
      "metadata": {
        "id": "Ola0zXNEUiKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import whisper\n",
        "import torchaudio\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "pKCM_fNETwKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LibriSpeech(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
        "    It will drop the last few seconds of a very small portion of the utterances.\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
        "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
        "            root=os.path.expanduser(\"~/.cache\"),\n",
        "            url=split,\n",
        "            download=True,\n",
        "        )\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
        "        assert sample_rate == 16000\n",
        "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
        "        mel = whisper.log_mel_spectrogram(audio)\n",
        "\n",
        "        return (mel, text)"
      ],
      "metadata": {
        "id": "lC5CiGxfT2Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LibriSpeech(\"test-clean\")\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
      ],
      "metadata": {
        "id": "zKpmOhsRT46r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running inference on the dataset using a base Whisper model\n",
        "\n",
        "The following will take a few minutes to transcribe all utterances in the dataset."
      ],
      "metadata": {
        "id": "E_fQpzuyT8YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base.en\")\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        ")"
      ],
      "metadata": {
        "id": "sHKAe80tT8yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict without timestamps for short-form transcription\n",
        "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
      ],
      "metadata": {
        "id": "Q21WQ1oJT_mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "for mels, texts in tqdm(loader):\n",
        "    results = model.decode(mels, options)\n",
        "    hypotheses.extend([result.text for result in results])\n",
        "    references.extend(texts)"
      ],
      "metadata": {
        "id": "hX1zggIvUB5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "data"
      ],
      "metadata": {
        "id": "-xYYXSp4UEKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the word error rate\n",
        "\n",
        "Now, we use our English normalizer implementation to standardize the transcription and calculate the WER."
      ],
      "metadata": {
        "id": "EfdXfpdqUGBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jiwer\n",
        "from whisper.normalizers import EnglishTextNormalizer\n",
        "\n",
        "normalizer = EnglishTextNormalizer()"
      ],
      "metadata": {
        "id": "bMVW_LbiUGnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
        "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\n",
        "data"
      ],
      "metadata": {
        "id": "_Ow4flcnUJ_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "Q_b6_fwMUOKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "xlhr8jxxUUzn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}